<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Audio Transcriber</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 40px;
            max-width: 800px;
            width: 100%;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            font-weight: 300;
        }

        .controls {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            margin-bottom: 30px;
        }

        .btn {
            padding: 15px 30px;
            border: none;
            border-radius: 50px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .btn-start {
            background: linear-gradient(45deg, #4CAF50, #45a049);
            color: white;
        }

        .btn-start:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(76, 175, 80, 0.3);
        }

        .btn-stop {
            background: linear-gradient(45deg, #f44336, #da190b);
            color: white;
        }

        .btn-stop:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(244, 67, 54, 0.3);
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .status {
            text-align: center;
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 10px;
            font-weight: 500;
            transition: all 0.3s ease;
        }

        .status.inactive {
            background: #f5f5f5;
            color: #666;
        }

        .status.listening {
            background: linear-gradient(45deg, #2196F3, #1976D2);
            color: white;
            animation: pulse 2s infinite;
        }

        .status.processing {
            background: linear-gradient(45deg, #FF9800, #F57C00);
            color: white;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.02); }
            100% { transform: scale(1); }
        }

        .audio-visualizer {
            height: 60px;
            background: #f0f0f0;
            border-radius: 10px;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        .audio-bars {
            display: flex;
            gap: 3px;
            height: 100%;
            align-items: center;
        }

        .bar {
            width: 4px;
            background: linear-gradient(to top, #667eea, #764ba2);
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        .transcription {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 15px;
            padding: 20px;
            min-height: 200px;
            font-size: 16px;
            line-height: 1.6;
            color: #333;
            overflow-y: auto;
            max-height: 400px;
        }

        .transcription-item {
            margin-bottom: 15px;
            padding: 10px;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .timestamp {
            font-size: 12px;
            color: #666;
            margin-bottom: 5px;
        }

        .settings {
            margin-top: 20px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
        }

        .setting-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }

        .setting-item label {
            font-weight: 500;
            color: #333;
        }

        .setting-item input {
            padding: 5px 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            width: 80px;
        }

        .error {
            background: #ffebee;
            color: #c62828;
            padding: 10px;
            border-radius: 5px;
            margin-bottom: 10px;
            border-left: 4px solid #f44336;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 Auto Voice Transcriber</h1>
        
        <div class="controls">
            <button id="startBtn" class="btn btn-start">Enable Auto Transcription</button>
            <button id="stopBtn" class="btn btn-stop" disabled>Disable Auto Transcription</button>
        </div>

        <div id="status" class="status inactive">
            Click "Enable Auto Transcription" to start automatic voice detection
        </div>

        <div class="audio-visualizer">
            <div class="audio-bars" id="audioBars">
                <!-- Audio bars will be generated here -->
            </div>
        </div>

        <div class="settings">
            <div class="setting-item">
                <label for="threshold">Voice Activation Threshold:</label>
                <input type="range" id="threshold" min="20" max="80" value="42">
                <span id="thresholdValue">35</span>
            </div>
            <div class="setting-item">
                <label for="silenceDuration">Auto-stop after silence (ms):</label>
                <input type="number" id="silenceDuration" value="2000" min="1000" max="5000">
            </div>
            <div class="setting-item">
                <label for="minRecordingTime">Minimum recording time (ms):</label>
                <input type="number" id="minRecordingTime" value="1000" min="500" max="3000">
            </div>
        </div>

        <div id="transcription" class="transcription">
            <p style="text-align: center; color: #666; font-style: italic;">
                Auto-transcriptions will appear here when you speak...
            </p>
        </div>
    </div>

    <script>
        class AutoVoiceTranscriber {
            constructor() {
                this.mediaRecorder = null;
                this.audioContext = null;
                this.analyser = null;
                this.microphone = null;
                this.dataArray = null;
                this.isActive = false;
                this.isRecording = false;
                this.audioChunks = [];
                this.silenceTimer = null;
                this.voiceThreshold = 35;
                this.silenceDuration = 2000;
                this.minRecordingTime = 1000;
                this.recordingStartTime = 0;
                this.consecutiveVoiceFrames = 0;
                this.consecutiveSilenceFrames = 0;
                this.requiredVoiceFrames = 3; // Need 3 consecutive frames above threshold
                this.requiredSilenceFrames = 10; // Need 10 consecutive frames below threshold
                
                this.initializeElements();
                this.setupEventListeners();
                this.createAudioBars();
            }

            initializeElements() {
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.status = document.getElementById('status');
                this.transcription = document.getElementById('transcription');
                this.audioBars = document.getElementById('audioBars');
                this.thresholdInput = document.getElementById('threshold');
                this.thresholdValue = document.getElementById('thresholdValue');
                this.silenceDurationInput = document.getElementById('silenceDuration');
                this.minRecordingTimeInput = document.getElementById('minRecordingTime');
            }

            setupEventListeners() {
                this.startBtn.addEventListener('click', () => this.enableAutoTranscription());
                this.stopBtn.addEventListener('click', () => this.disableAutoTranscription());
                
                this.thresholdInput.addEventListener('input', (e) => {
                    this.voiceThreshold = parseInt(e.target.value);
                    this.thresholdValue.textContent = this.voiceThreshold;
                });
                
                this.silenceDurationInput.addEventListener('input', (e) => {
                    this.silenceDuration = parseInt(e.target.value);
                });
                
                this.minRecordingTimeInput.addEventListener('input', (e) => {
                    this.minRecordingTime = parseInt(e.target.value);
                });
            }

            createAudioBars() {
                for (let i = 0; i < 20; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'bar';
                    bar.style.height = '10px';
                    this.audioBars.appendChild(bar);
                }
            }

            async enableAutoTranscription() {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true
                        }
                    });
                    
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();
                    this.microphone = this.audioContext.createMediaStreamSource(stream);
                    
                    this.analyser.fftSize = 512;
                    this.analyser.smoothingTimeConstant = 0.8;
                    this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
                    
                    this.microphone.connect(this.analyser);
                    
                    this.mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });
                    this.setupMediaRecorder();
                    
                    this.isActive = true;
                    this.startBtn.disabled = true;
                    this.stopBtn.disabled = false;
                    
                    this.updateStatus('🎯 Auto-detection active - Waiting for voice...', 'listening');
                    this.startContinuousAnalysis();
                    
                } catch (error) {
                    console.error('Error accessing microphone:', error);
                    this.showError('Could not access microphone. Please check permissions.');
                }
            }

            setupMediaRecorder() {
                this.mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        this.audioChunks.push(event.data);
                    }
                };
                
                this.mediaRecorder.onstop = () => {
                    const recordingDuration = Date.now() - this.recordingStartTime;
                    
                    if (this.audioChunks.length > 0 && recordingDuration >= this.minRecordingTime) {
                        const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                        this.sendAudioForTranscription(audioBlob);
                    } else {
                        console.log('Recording too short, skipping transcription');
                        if (this.isActive) {
                            this.updateStatus('🎯 Auto-detection active - Waiting for voice...', 'listening');
                        }
                    }
                    
                    this.audioChunks = [];
                    this.isRecording = false;
                };
            }

            startContinuousAnalysis() {
                const analyzeAudio = () => {
                    if (!this.isActive) return;
                    
                    this.analyser.getByteFrequencyData(this.dataArray);
                    
                    // Calculate volume with emphasis on voice frequencies (300-3000 Hz)
                    const voiceFreqStart = Math.floor(300 / (this.audioContext.sampleRate / 2) * this.dataArray.length);
                    const voiceFreqEnd = Math.floor(3000 / (this.audioContext.sampleRate / 2) * this.dataArray.length);
                    
                    let voiceSum = 0;
                    for (let i = voiceFreqStart; i < voiceFreqEnd; i++) {
                        voiceSum += this.dataArray[i];
                    }
                    
                    const voiceAverage = voiceSum / (voiceFreqEnd - voiceFreqStart);
                    const normalizedVolume = (voiceAverage / 255) * 100;
                    
                    // Update visualizer
                    this.updateVisualizer(this.dataArray);
                    
                    // Voice activity detection with hysteresis
                    if (normalizedVolume > this.voiceThreshold) {
                        this.consecutiveVoiceFrames++;
                        this.consecutiveSilenceFrames = 0;
                        
                        if (this.consecutiveVoiceFrames >= this.requiredVoiceFrames && !this.isRecording) {
                            this.startAutoRecording();
                        }
                    } else {
                        this.consecutiveSilenceFrames++;
                        this.consecutiveVoiceFrames = 0;
                        
                        if (this.consecutiveSilenceFrames >= this.requiredSilenceFrames && this.isRecording) {
                            this.stopAutoRecording();
                        }
                    }
                    
                    requestAnimationFrame(analyzeAudio);
                };
                
                analyzeAudio();
            }

            updateVisualizer(dataArray) {
                const bars = this.audioBars.children;
                for (let i = 0; i < bars.length; i++) {
                    const value = dataArray[i] || 0;
                    const height = (value / 255) * 50 + 5;
                    bars[i].style.height = `${height}px`;
                }
            }

            startAutoRecording() {
                if (this.mediaRecorder && this.mediaRecorder.state === 'inactive') {
                    this.mediaRecorder.start();
                    this.isRecording = true;
                    this.recordingStartTime = Date.now();
                    this.updateStatus('🔴 Recording voice automatically...', 'processing');
                    console.log('🎤 Auto-recording started');
                }
            }

            stopAutoRecording() {
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                    console.log('⏹️ Auto-recording stopped');
                    this.updateStatus('🔄 Processing audio...', 'processing');
                }
            }

            async sendAudioForTranscription(audioBlob) {
                try {
                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'audio.webm');
                    
                    console.log('📤 Sending audio for transcription...');
                    
                    const response = await fetch('/transcribe', {
                        method: 'POST',
                        body: formData
                    });
                    
                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }
                    
                    const result = await response.json();
                    this.displayTranscription(result);
                    
                    if (this.isActive) {
                        this.updateStatus('🎯 Auto-detection active - Waiting for voice...', 'listening');
                    }
                    
                } catch (error) {
                    console.error('❌ Transcription error:', error);
                    this.showError('Transcription failed. Please try again.');
                    
                    if (this.isActive) {
                        this.updateStatus('🎯 Auto-detection active - Waiting for voice...', 'listening');
                    }
                }
            }

            displayTranscription(result) {
                if (this.transcription.innerHTML.includes('Auto-transcriptions will appear here')) {
                    this.transcription.innerHTML = '';
                }
                
                const transcriptionItem = document.createElement('div');
                transcriptionItem.className = 'transcription-item';
                
                const timestamp = document.createElement('div');
                timestamp.className = 'timestamp';
                timestamp.textContent = new Date().toLocaleTimeString();
                
                const text = document.createElement('div');
                text.textContent = result.transcription || 'No transcription available';
                
                transcriptionItem.appendChild(timestamp);
                transcriptionItem.appendChild(text);
                
                this.transcription.appendChild(transcriptionItem);
                this.transcription.scrollTop = this.transcription.scrollHeight;
            }

            disableAutoTranscription() {
                this.isActive = false;
                this.isRecording = false;
                this.consecutiveVoiceFrames = 0;
                this.consecutiveSilenceFrames = 0;
                
                if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
                    this.mediaRecorder.stop();
                }
                
                if (this.audioContext) {
                    this.audioContext.close();
                }
                
                this.startBtn.disabled = false;
                this.stopBtn.disabled = true;
                
                this.updateStatus('⏸️ Auto-transcription disabled', 'inactive');
                this.resetVisualizer();
                
                console.log('🛑 Auto-transcription disabled');
            }

            resetVisualizer() {
                const bars = this.audioBars.children;
                for (let bar of bars) {
                    bar.style.height = '10px';
                }
            }

            updateStatus(message, type) {
                this.status.textContent = message;
                this.status.className = `status ${type}`;
            }

            showError(message) {
                const errorDiv = document.createElement('div');
                errorDiv.className = 'error';
                errorDiv.textContent = message;
                
                this.transcription.insertBefore(errorDiv, this.transcription.firstChild);
                
                setTimeout(() => {
                    if (errorDiv.parentNode) {
                        errorDiv.parentNode.removeChild(errorDiv);
                    }
                }, 5000);
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            new AutoVoiceTranscriber();
        });
    </script>
</body>
</html>
